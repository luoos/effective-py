{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency and Parallelism\n",
    "\n",
    "**Concurrency** is when a computer does many different things *seemingly* at the same time.\n",
    "\n",
    "**Parallelism** is *actually* doing many different things at the same time.\n",
    "\n",
    "The key difference between parallelism and concurrency is *speedup*.\n",
    "\n",
    "Python makes it easy to write concurrent programs. But it can be very difficult to make concurrent Python code truly run in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Item 36: Use subprocess to Manage Child Processes](#Item-36:-Use-subprocess-to-Manage-Child-Processes)\n",
    "- [Item 37: Use Threads for Blocking I/O, Avoid for Parallelism](#Item-37:-Use-Threads-for-Blocking-I/O,-Avoid-for-Parallelism)\n",
    "- [Item 38: Use Lock to Prevent Data Races in Threads](#Item-38:-Use-Lock-to-Prevent-Data-Races-in-Threads)\n",
    "- [Item 39: Use Queue to Coordinate Work Between Threads](#Item-39:-Use-Queue-to-Coordinate-Work-Between-Threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 36: Use *subprocess* to Manage Child Processes\n",
    "\n",
    "With the Python of today, the best and simplest choice for managing child processes is to use the *subprocess* built-in module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "proc = subprocess.Popen(\n",
    "        ['echo', 'Hello from the child'],\n",
    "        stdout=subprocess.PIPE)\n",
    "out, err = proc.communicate()\n",
    "print(out.decode('utf-8'))\n",
    "\n",
    "print('starting')\n",
    "proc = subprocess.Popen(['sleep', '1'])\n",
    "print('started')\n",
    "proc.communicate()\n",
    "print('communicated')\n",
    "while proc.poll() is None:\n",
    "    pass\n",
    "    \n",
    "print('Exit status', proc.poll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def run_sleep(period):\n",
    "    proc = subprocess.Popen(['sleep', str(period)])\n",
    "    return proc\n",
    "\n",
    "start = time()\n",
    "procs = []\n",
    "for _ in range(10):\n",
    "    proc = run_sleep(0.1)\n",
    "    procs.append(proc)\n",
    "    \n",
    "for proc in procs:\n",
    "    proc.communicate()\n",
    "end = time()\n",
    "print('Finished in %.3f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_openssl(data):\n",
    "    env = os.environ.copy()\n",
    "    env['password'] = b'\\xe24U\\n\\xd0Ql3S\\x11'\n",
    "    proc = subprocess.Popen(\n",
    "        ['openssl', 'enc', '-des3', '-pass', 'env:password'],\n",
    "        env=env,\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE)\n",
    "    proc.stdin.write(data)\n",
    "    proc.stdin.flush()\n",
    "    return proc\n",
    "\n",
    "procs = []\n",
    "for _ in range(3):\n",
    "    data = os.urandom(10)\n",
    "    proc = run_openssl(data)\n",
    "    procs.append(proc)\n",
    "    \n",
    "for proc in procs:\n",
    "    out, err = proc.communicate()\n",
    "    print(out[-10:])\n",
    "    \n",
    "def run_md5(input_stdin):\n",
    "    proc = subprocess.Popen(\n",
    "        ['md5'],\n",
    "        stdin=input_stdin,\n",
    "        stdout=subprocess.PIPE)\n",
    "    return proc\n",
    "\n",
    "input_procs = []\n",
    "hash_procs = []\n",
    "for _ in range(3):\n",
    "    data = os.urandom(10)\n",
    "    proc = run_openssl(data)\n",
    "    input_procs.append(proc)\n",
    "    hash_proc = run_md5(proc.stdout)\n",
    "    hash_procs.append(hash_proc)\n",
    "    \n",
    "for proc in input_procs:\n",
    "    proc.communicate()\n",
    "for proc in hash_procs:\n",
    "    out, err = proc.communicate()\n",
    "    print(out.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sleep(period):\n",
    "    proc = subprocess.Popen(['sleep', str(period)])\n",
    "    return proc\n",
    "\n",
    "proc = run_sleep(10)\n",
    "try:\n",
    "    proc.communicate(timeout=0.1)\n",
    "except subprocess.TimeoutExpired:\n",
    "    proc.terminate()\n",
    "    proc.wait()\n",
    "    \n",
    "print('Exit status', proc.poll())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "- Use the *subprocess* module to run child processes and manage their input and output streams.\n",
    "- Child processes run in parallel with the Python interpreter, enabling you to maximize your CPU usage.\n",
    "- Use the *timeout* parameter with *communicate* to avoid deadlocks and hanging child processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 37: Use Threads for Blocking I/O, Avoid for Parallelism\n",
    "\n",
    "Python enforces coherence with a mechanism called the *global interpreter lock* (GIL).\n",
    "\n",
    "The GIL has an important negative side effect. Although Python supports multiple threads of execution, the GIL causes only one of them to make forward progress at a time. This means that when you reach for threads to do parallel computation and speed up your Python programs, you will be sorely disappointed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def factorize(number):\n",
    "    for i in range(1, number + 1):\n",
    "        if number % i == 0:\n",
    "            yield i\n",
    "            \n",
    "    \n",
    "numbers = [2139079, 218502, 589213, 789123]\n",
    "start = time()\n",
    "for number in numbers:\n",
    "    list(factorize(number))\n",
    "end = time()\n",
    "print('Took %.3f seconds' % (end - start))\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "class FactorizeThread(Thread):\n",
    "    def __init__(self, number):\n",
    "        super().__init__()\n",
    "        self.number = number\n",
    "        \n",
    "    def run(self):\n",
    "        self.factors = list(factorize(self.number))\n",
    "        \n",
    "start = time()\n",
    "threads = []\n",
    "for number in numbers:\n",
    "    thread = FactorizeThread(number)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "end = time()\n",
    "# Even longer with multithread\n",
    "print('Took %.3f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ways to get CPython to utilize multiple cores, but it doesn't work with the standard **Thread** class and it can require substantial effort.\n",
    "\n",
    "Why does Python support threads at all?\n",
    "\n",
    "1. Multiple threads make it easy for your program to seem like it's doing multiple things at the same time.\n",
    "2. Python supports threads is to deal with blocking I/O, which happens when Python does certain types of system calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import select\n",
    "\n",
    "def slow_systemcall():\n",
    "    select.select([], [], [], 0.1)\n",
    "    \n",
    "start = time()\n",
    "for _ in range(5):\n",
    "    slow_systemcall()\n",
    "end = time()\n",
    "print('Took %.3f seconds' % (end - start))\n",
    "\n",
    "start = time()\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    thread = Thread(target=slow_systemcall)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "end = time()\n",
    "print('Took %.3f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GIL prevents Python code from running in parallel, but it has no negative effect on system calls. This works because Python threads release the GIL just before they make system calls and reacquire the GIL as soon as the system calls are done.\n",
    "\n",
    "### Things to Remember\n",
    "\n",
    "- Python threads can't run bytecode in parallel on multiple CPU cores because of the global interpreter lock (GIL)\n",
    "- Python threads are still useful despite the GIL because they provide an easy way to do multiple things at seemingly the same time.\n",
    "- Use Python threads to make multiple system calls in parallel. This allows you to do blocking I/O at the same time as computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 38: Use *Lock* to Prevent Data Races in Threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global interpreter lock (GIL) will not protect you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        \n",
    "    def increment(self, offset):\n",
    "        self.count += offset\n",
    "        \n",
    "def worker(sensor_index, how_many, counter):\n",
    "    for _ in range(how_many):\n",
    "        counter.increment(1)\n",
    "        \n",
    "def run_threads(func, how_many, counter):\n",
    "    threads = []\n",
    "    for i in range(5):\n",
    "        args = (i, how_many, counter)\n",
    "        thread = Thread(target=func, args=args)\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "        \n",
    "how_many = 10**5\n",
    "counter = Counter()\n",
    "start = time()\n",
    "run_threads(worker, how_many, counter)\n",
    "end = time()\n",
    "print('Counter should be %d, found %d, time: %.3f' %\n",
    "      (5 * how_many, counter.count, end - start))\n",
    "\n",
    "from threading import Lock\n",
    "\n",
    "class LockingCounter(object):\n",
    "    def __init__(self):\n",
    "        self.lock = Lock()\n",
    "        self.count = 0\n",
    "        \n",
    "    def increment(self, offset):\n",
    "        with self.lock:\n",
    "            self.count += offset\n",
    "            \n",
    "counter = LockingCounter()\n",
    "start = time()\n",
    "run_threads(worker, how_many, counter)\n",
    "end = time()\n",
    "print('Locking Counter should be %d, found %d, time: %.3f' %\n",
    "      (5 * how_many, counter.count, end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "- Even though Python has a global interpreter lock, you're still responsible for protecting against data races between the threads in your programs.\n",
    "- Your programs will corrupt their data structures if you allow multiple threads to modify the same objects without locks.\n",
    "- The Lock class in the threading built-in module is Python's standard mutual exclusion lock implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 39: Use Queue to Coordinate Work Between Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from time import sleep\n",
    "\n",
    "class MyQueue(object):\n",
    "    def __init__(self):\n",
    "        self.items = deque()\n",
    "        self.lock = Lock()\n",
    "        \n",
    "    def put(self, item):\n",
    "        with self.lock:\n",
    "            self.items.append(item)\n",
    "            \n",
    "    def get(self):\n",
    "        with self.lock:\n",
    "            return self.items.popleft()\n",
    "        \n",
    "        \n",
    "class Worker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        self.polled_count = 0\n",
    "        self.work_done = 0\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            self.polled_count += 1\n",
    "            try:\n",
    "                item = self.in_queue.get()\n",
    "            except IndexError:\n",
    "                sleep(0.01)  # No work to do\n",
    "            else:\n",
    "                result = self.func(item)\n",
    "                self.out_queue.put(result)\n",
    "                self.work_done += 1\n",
    "\n",
    "def download(item):\n",
    "    sleep(0.001)\n",
    "    \n",
    "def resize(item):\n",
    "    sleep(0.00001)\n",
    "    \n",
    "def upload(item):\n",
    "    sleep(0.001)\n",
    "                \n",
    "download_queue = MyQueue()\n",
    "resize_queue = MyQueue()\n",
    "upload_queue = MyQueue()\n",
    "done_queue = MyQueue()\n",
    "threads = [\n",
    "    Worker(download, download_queue, resize_queue),\n",
    "    Worker(resize, resize_queue, upload_queue),\n",
    "    Worker(upload, upload_queue, done_queue),\n",
    "]\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    \n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())\n",
    "    \n",
    "while len(done_queue.items) < 1000:\n",
    "    sleep(0.1)\n",
    "    \n",
    "processed = len(done_queue.items)\n",
    "polled = sum(t.polled_count for t in threads)\n",
    "print('Proccessd', processed, 'items after polling',\n",
    "      polled, 'times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three problems with above implementation:\n",
    "\n",
    "1. busy wait on the *done_queue*\n",
    "2. In *Worker* the *run* method will execute forever in its busy loop. There's no way to signal to a worker thread that it's time to exit.\n",
    "3. Out of memory for a slow queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queue to the Rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "\n",
    "queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Comsumer waiting')\n",
    "    queue.get()\n",
    "    print('Consumer done')\n",
    "    \n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "print('Producer putting')\n",
    "queue.put(object())\n",
    "thread.join()\n",
    "print('Producer done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from time import sleep\n",
    "\n",
    "queue = Queue(1)\n",
    "\n",
    "def consumer():\n",
    "    sleep(0.1)\n",
    "    queue.get()\n",
    "    print('Consumer got 1')\n",
    "    queue.get()\n",
    "    print('Consumer got 2')\n",
    "    \n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "queue.put(object())\n",
    "print('Producer put 1')\n",
    "queue.put(object())\n",
    "print('Producer put 2')\n",
    "thread.join()\n",
    "print('Producer done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "in_queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    work = in_queue.get()\n",
    "    print('Consumer working 1')\n",
    "    work = in_queue.get()\n",
    "    print('Consumer working 2')\n",
    "    print('Consumer done')\n",
    "    in_queue.task_done()\n",
    "    in_queue.task_done()\n",
    "    \n",
    "Thread(target=consumer).start()\n",
    "in_queue.put(object())\n",
    "print('Producer put 1')\n",
    "in_queue.put(object())\n",
    "print('Producer put 2')\n",
    "print('Producer waiting')\n",
    "in_queue.join()\n",
    "print('Producer done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "class ClosableQueue(Queue):\n",
    "    SENTINEL = object()\n",
    "    \n",
    "    def close(self):\n",
    "        self.put(self.SENTINEL)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            item = self.get()\n",
    "            try:\n",
    "                if item is self.SENTINEL:\n",
    "                    return  # Exit\n",
    "                yield item\n",
    "            finally:\n",
    "                self.task_done()\n",
    "                \n",
    "\n",
    "class StoppableWorker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        \n",
    "    def run(self):\n",
    "        for item in self.in_queue:\n",
    "            result = self.func(item)\n",
    "            self.out_queue.put(result)\n",
    "            \n",
    "def download(item):\n",
    "    sleep(0.001)\n",
    "    \n",
    "def resize(item):\n",
    "    sleep(0.00001)\n",
    "    \n",
    "def upload(item):\n",
    "    sleep(0.001)\n",
    "\n",
    "download_queue = ClosableQueue()\n",
    "resize_queue = ClosableQueue()\n",
    "upload_queue = ClosableQueue()\n",
    "done_queue = ClosableQueue()\n",
    "\n",
    "threads = [\n",
    "    StoppableWorker(download, download_queue, resize_queue),\n",
    "    StoppableWorker(resize, resize_queue, upload_queue),\n",
    "    StoppableWorker(upload, upload_queue, done_queue),\n",
    "]\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for _ in range(10):\n",
    "    download_queue.put(object())\n",
    "download_queue.close()\n",
    "download_queue.join()\n",
    "resize_queue.close()\n",
    "resize_queue.join()\n",
    "upload_queue.close()\n",
    "upload_queue.join()\n",
    "print(done_queue.qsize(), 'items finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "- Pipelines are a great way to organize sequences of work that run concurrently using multiple Python threads.\n",
    "- Be aware of the many problems in building concurrent pipelines: busy waiting, stopping workers, and memory explosion.\n",
    "- The **Queue** class has all of the facilities you need to build robust pipelines: blocking operations, buffer sizes, and joining."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
